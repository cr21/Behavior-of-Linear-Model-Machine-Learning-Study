{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "LinearModel_ColinearFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cr21/Behavior-of-Linear-Model-Machine-Learning-Study/blob/main/LinearModel_ColinearFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86Tvnj5UblTy"
      },
      "source": [
        "##  Collinear features and their effect on linear models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrJ3kkq5knSq",
        "outputId": "4052a91c-0ab5-44eb-bc7b-4c1d9cb06cfe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn_eOn2EblT3"
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import  LinearSVC"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdm4YRKWk9FJ",
        "outputId": "1e556cd8-65a2-4b7c-aa2d-c56225d0a009"
      },
      "source": [
        "cd drive/MyDrive/AI_dataset/8_LinearModels/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1BiHVEnsCpP-UmVK0W6upN-kOzI1a93Sb/8_LinearModels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMoYWIayblUB"
      },
      "source": [
        "data = pd.read_csv('task_d.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfStXG4tblUI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "18e6458b-1059-455a-ceff-261bf88f891f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>x*x</th>\n",
              "      <th>2*y</th>\n",
              "      <th>2*z+3*x*x</th>\n",
              "      <th>w</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.581066</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-0.604025</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>-0.665927</td>\n",
              "      <td>-0.536277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.894309</td>\n",
              "      <td>-0.207835</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-0.883052</td>\n",
              "      <td>-0.207835</td>\n",
              "      <td>-0.917054</td>\n",
              "      <td>-0.522364</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.207552</td>\n",
              "      <td>0.212034</td>\n",
              "      <td>-1.082312</td>\n",
              "      <td>-1.150918</td>\n",
              "      <td>0.212034</td>\n",
              "      <td>-1.166507</td>\n",
              "      <td>0.205738</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.364174</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.943643</td>\n",
              "      <td>-1.280666</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-1.266540</td>\n",
              "      <td>-0.665720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.737687</td>\n",
              "      <td>1.051772</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-0.744934</td>\n",
              "      <td>1.051772</td>\n",
              "      <td>-0.792746</td>\n",
              "      <td>-0.735054</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          x         y         z  ...  2*z+3*x*x         w  target\n",
              "0 -0.581066  0.841837 -1.012978  ...  -0.665927 -0.536277       0\n",
              "1 -0.894309 -0.207835 -1.012978  ...  -0.917054 -0.522364       0\n",
              "2 -1.207552  0.212034 -1.082312  ...  -1.166507  0.205738       0\n",
              "3 -1.364174  0.002099 -0.943643  ...  -1.266540 -0.665720       0\n",
              "4 -0.737687  1.051772 -1.012978  ...  -0.792746 -0.735054       0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIIuomCkblUP"
      },
      "source": [
        "X = data.drop(['target'], axis=1).values\n",
        "Y = data['target'].values"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydm98u3EblUU"
      },
      "source": [
        "### Doing perturbation test to check the presence of collinearity  \n",
        "\n",
        "#### 1. Experiment 1 Logistic Regression\n",
        "<pre>\n",
        "\n",
        "\n",
        "1. <b>Finding the Correlation between the features</b>\n",
        "    a. check the correlation between the features\n",
        "    b. plot heat map of correlation matrix using seaborn heatmap\n",
        "2. <b>Finding the best model for the given data</b>\n",
        "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
        "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
        "    random search CV make sure you choose the alpha in log space)\n",
        "    c. Creat a new Logistic regression with the best alpha\n",
        "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
        "    \n",
        "3. <b>Getting the weights with the original data</b>\n",
        "    a. train the 'best_model' with X, Y\n",
        "    b. Check the accuracy of the model 'best_model_accuracy'\n",
        "    c. Get the weights W using best_model.coef_\n",
        "\n",
        "4. <b>Modifying original data</b>\n",
        "    a. Add a noise(order of 10^-2) to each element of X \n",
        "    and get the new data set X' (X' = X + e)\n",
        "    b. Train the same 'best_model' with data (X', Y)\n",
        "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
        "    d. Get the weights W' using best_model.coef_\n",
        "    \n",
        "5. <b> Checking deviations in metric and weights </b>\n",
        "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
        "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
        "    c. print the top 4 features which have higher % change in weights \n",
        "    compare to the other feature\n",
        "\n",
        "</pre>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbEpJin8l4up"
      },
      "source": [
        "<pre>\n",
        "1.1 <b>Finding the Correlation between the features</b>\n",
        "    a. check the correlation between the features\n",
        "    b. plot heat map of correlation matrix using seaborn heatmap\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Ok_vCUM3nnAm",
        "outputId": "e6b1cd19-2d3c-4604-a2a2-4028a131a689"
      },
      "source": [
        "# a. checking the corelation between features\n",
        "corelationMatrix = data.corr()\n",
        "corelationMatrix\n",
        "# https://www.youtube.com/watch?v=JwNwbu-g2m0&ab_channel=TopTipBio"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>x*x</th>\n",
              "      <th>2*y</th>\n",
              "      <th>2*z+3*x*x</th>\n",
              "      <th>w</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.205926</td>\n",
              "      <td>0.812458</td>\n",
              "      <td>0.997947</td>\n",
              "      <td>-0.205926</td>\n",
              "      <td>0.996252</td>\n",
              "      <td>0.583277</td>\n",
              "      <td>0.728290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>-0.205926</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.602663</td>\n",
              "      <td>-0.209289</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.261123</td>\n",
              "      <td>-0.401790</td>\n",
              "      <td>-0.690684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>0.812458</td>\n",
              "      <td>-0.602663</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.807137</td>\n",
              "      <td>-0.602663</td>\n",
              "      <td>0.847163</td>\n",
              "      <td>0.674486</td>\n",
              "      <td>0.969990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x*x</th>\n",
              "      <td>0.997947</td>\n",
              "      <td>-0.209289</td>\n",
              "      <td>0.807137</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.209289</td>\n",
              "      <td>0.997457</td>\n",
              "      <td>0.583803</td>\n",
              "      <td>0.719570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2*y</th>\n",
              "      <td>-0.205926</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.602663</td>\n",
              "      <td>-0.209289</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.261123</td>\n",
              "      <td>-0.401790</td>\n",
              "      <td>-0.690684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2*z+3*x*x</th>\n",
              "      <td>0.996252</td>\n",
              "      <td>-0.261123</td>\n",
              "      <td>0.847163</td>\n",
              "      <td>0.997457</td>\n",
              "      <td>-0.261123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.606860</td>\n",
              "      <td>0.764729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>w</th>\n",
              "      <td>0.583277</td>\n",
              "      <td>-0.401790</td>\n",
              "      <td>0.674486</td>\n",
              "      <td>0.583803</td>\n",
              "      <td>-0.401790</td>\n",
              "      <td>0.606860</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.641750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0.728290</td>\n",
              "      <td>-0.690684</td>\n",
              "      <td>0.969990</td>\n",
              "      <td>0.719570</td>\n",
              "      <td>-0.690684</td>\n",
              "      <td>0.764729</td>\n",
              "      <td>0.641750</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  x         y         z  ...  2*z+3*x*x         w    target\n",
              "x          1.000000 -0.205926  0.812458  ...   0.996252  0.583277  0.728290\n",
              "y         -0.205926  1.000000 -0.602663  ...  -0.261123 -0.401790 -0.690684\n",
              "z          0.812458 -0.602663  1.000000  ...   0.847163  0.674486  0.969990\n",
              "x*x        0.997947 -0.209289  0.807137  ...   0.997457  0.583803  0.719570\n",
              "2*y       -0.205926  1.000000 -0.602663  ...  -0.261123 -0.401790 -0.690684\n",
              "2*z+3*x*x  0.996252 -0.261123  0.847163  ...   1.000000  0.606860  0.764729\n",
              "w          0.583277 -0.401790  0.674486  ...   0.606860  1.000000  0.641750\n",
              "target     0.728290 -0.690684  0.969990  ...   0.764729  0.641750  1.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lai8wXU1pmSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "846b6f87-dfbb-42a6-a336-181d28006617"
      },
      "source": [
        "# b. plotting the heat map\n",
        "sns.heatmap(corelationMatrix )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9332073c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAmHchSwqrTE"
      },
      "source": [
        "<pre>\n",
        "\n",
        "1.2. <b>Finding the best model for the given data</b>\n",
        "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
        "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
        "    random search CV make sure you choose the alpha in log space)\n",
        "    c. Creat a new Logistic regression with the best alpha\n",
        "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRUf1MMSqqmm",
        "outputId": "a7acf37e-a271-4afb-862f-a8b8817821f6"
      },
      "source": [
        "# https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
        "logistic = LogisticRegression(max_iter=10000, tol=0.1, penalty='l2')\n",
        "pipe = Pipeline(steps=[ ('logistic', logistic)])\n",
        "folds = KFold(5)\n",
        "param_grid = {\n",
        "    'logistic__C': np.logspace(-4, 4, 5)\n",
        "}\n",
        "\n",
        "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=folds)\n",
        "\n",
        "search.fit(X, Y)\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "print(search.best_params_)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=1.000):\n",
            "{'logistic__C': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2cP8uyvDIE"
      },
      "source": [
        "<pre>\n",
        "1.3. <b>Getting the weights with the original data</b>\n",
        "    a. train the 'best_model' with X, Y\n",
        "    b. Check the accuracy of the model 'best_model_accuracy'\n",
        "    c. Get the weights W using best_model.coef_\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liqF6EAYuD0F",
        "outputId": "594bc328-4cd7-478a-fabb-2a071a7b0af2"
      },
      "source": [
        "# create new logistic regression model with best alpha value\n",
        "best_C = search.best_params_['logistic__C']\n",
        "best_logistic_model = LogisticRegression(C=best_C)\n",
        "best_logistic_model.fit(X,Y)\n",
        "best_logistic_model_accuracy = best_logistic_model.score(X,Y)\n",
        "print(f\" best logistic model accuracy\", best_logistic_model_accuracy)\n",
        "best_logistic_model_weights = best_logistic_model.coef_\n",
        "print(f\"Best logistic model coefficents\", best_logistic_model_weights)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " best logistic model accuracy 1.0\n",
            "Best logistic model coefficents [[ 0.72298832 -0.90354834  1.68256456  0.66730582 -0.90354834  0.80372108\n",
            "   0.5096727 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0vmC_uxu6j-"
      },
      "source": [
        "<pre>\n",
        "1.4. <b>Modifying original data</b>\n",
        "    a. Add a noise(order of 10^-2) to each element of X \n",
        "    and get the new data set X' (X' = X + e)\n",
        "    b. Train the same 'best_model' with data (X', Y)\n",
        "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
        "    d. Get the weights W' using best_model.coef_\n",
        "    \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgLaFw0Hv5Ws",
        "outputId": "9cd9d71b-4e20-4517-bc5d-611fe7c93e30"
      },
      "source": [
        "#  added gaussian noise in order of 10^-2\n",
        "\n",
        "X = X + np.random.normal(0,10**-2,X.shape)\n",
        "# train best model on noisy data\n",
        "best_logistic_model = LogisticRegression(C=best_C)\n",
        "best_logistic_model.fit(X,Y)\n",
        "\n",
        "# best_logistic_model.fit(X,Y)\n",
        "best_logistic_model_accuracy_edited = best_logistic_model.score(X,Y)\n",
        "print(f\" best logistic model accuracy edited \", best_logistic_model_accuracy_edited)\n",
        "best_logistic_model_weights_edited = best_logistic_model.coef_\n",
        "print(f\"Best logistic model coefficents edited\", best_logistic_model_weights_edited)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " best logistic model accuracy edited  1.0\n",
            "Best logistic model coefficents edited [[ 0.7247558  -0.90454959  1.67916368  0.67067216 -0.90852578  0.8019142\n",
            "   0.51241448]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mcaa4on0Ib3"
      },
      "source": [
        "<pre>\n",
        "5. <b> Checking deviations in metric and weights </b>\n",
        "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
        "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
        "    c. print the top 4 features which have higher % change in weights \n",
        "    compare to the other feature\n",
        "\n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmNdVOB2z9EE",
        "outputId": "83cb714e-2d84-48a6-88d8-6c84ac55b806"
      },
      "source": [
        "difference = abs(best_logistic_model_accuracy_edited - best_logistic_model_accuracy)\n",
        "print(\"difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\", difference)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "difference between 'best_model_accuracy_edited' and 'best_model_accuracy' 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0xazVQ70kNV",
        "outputId": "777e34e1-0342-4e66-905e-b27b6f84d2b5"
      },
      "source": [
        "\n",
        "abs_weight_difference = abs(best_logistic_model_weights - best_logistic_model_weights_edited)\n",
        "print(f\"absolute weights difference\", abs_weight_difference)\n",
        "abs_weight_percent_diff = abs_weight_difference*100\n",
        "print(f\"absolute weights percent difference\", abs_weight_percent_diff)\n",
        "\n",
        "top4 = np.argsort(-abs_weight_percent_diff)[:,:4]\n",
        "print('Top 4 feature index ',top4[:4]) #Top 4 feture index with highest difference in weights\n",
        "\n",
        "features = data.columns\n",
        "\n",
        "print(\"Top 4 features having highest absolute percentage weight change are\", features[top4])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absolute weights difference [[0.00176748 0.00100124 0.00340088 0.00336634 0.00497744 0.00180688\n",
            "  0.00274178]]\n",
            "absolute weights percent difference [[0.17674816 0.10012428 0.34008815 0.33663424 0.49774396 0.18068811\n",
            "  0.27417836]]\n",
            "Top 4 feature index  [[4 2 3 6]]\n",
            "Top 4 features having highest absolute percentage weight change are [['2*y' 'z' 'x*x' 'w']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky4HuNcQljvC"
      },
      "source": [
        "#### Experiment: 2 Linear SVM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMrUUOi03Tpa"
      },
      "source": [
        "<pre>\n",
        "\n",
        "1.2. <b>Finding the best SVM model for the given data</b>\n",
        "    a. Train SVM Model on data(X,Y) that we have created in the above cell\n",
        "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
        "    random search CV make sure you choose the alpha in log space)\n",
        "    c. Creat a new SVM   with the best alpha\n",
        "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlWsuftZ3TZS",
        "outputId": "2720c834-056a-40d1-832e-0c206f4a8b94"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py\n",
        "X = data.drop(['target'], axis=1).values\n",
        "Y = data['target'].values\n",
        "\n",
        "svm = LinearSVC( penalty='l2', max_iter=10000, tol=0.1)\n",
        "pipe = Pipeline(steps=[ ('svm', svm)])\n",
        "folds = KFold(5)\n",
        "param_grid = {\n",
        "    'svm__C': np.logspace(-4, 4, 5)\n",
        "}\n",
        "\n",
        "search_svm = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=folds)\n",
        "\n",
        "search_svm.fit(X, Y)\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search_svm.best_score_)\n",
        "print(search_svm.best_params_)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=1.000):\n",
            "{'svm__C': 0.0001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94PPP_AN7WbV"
      },
      "source": [
        "<pre>\n",
        "1.3. <b>Getting the weights with the original data</b>\n",
        "    a. train the 'best_model' with X, Y\n",
        "    b. Check the accuracy of the model 'best_model_accuracy'\n",
        "    c. Get the weights W using best_model.coef_\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz3f0sfk7a6o",
        "outputId": "66d2035f-29b6-40e9-e255-322b5288b579"
      },
      "source": [
        "# create new logistic regression model with best alpha value\n",
        "best_C = search_svm.best_params_['svm__C']\n",
        "best_svm_model = LinearSVC(C=best_C)\n",
        "best_svm_model.fit(X,Y)\n",
        "best_svm_model_accuracy = best_svm_model.score(X,Y)\n",
        "print(f\" best svm model accuracy\", best_svm_model_accuracy)\n",
        "best_svm_model_weights = best_svm_model.coef_\n",
        "print(f\"Best svm model coefficents\", best_svm_model_weights)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " best svm model accuracy 1.0\n",
            "Best svm model coefficents [[ 0.01323056 -0.01280974  0.01791372  0.01305589 -0.01280974  0.01391318\n",
            "   0.01167827]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY6xyfXA8Eh8"
      },
      "source": [
        "<pre>\n",
        "1.4. <b>Modifying original data</b>\n",
        "    a. Add a noise(order of 10^-2) to each element of X \n",
        "    and get the new data set X' (X' = X + e)\n",
        "    b. Train the same 'best_model' with data (X', Y)\n",
        "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
        "    d. Get the weights W' using best_model.coef_\n",
        "    \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dmws4H17u8J",
        "outputId": "1538fde8-785e-4413-ae78-5b957eb51c03"
      },
      "source": [
        "#  added gaussian noise in order of 10^-2\n",
        "\n",
        "X = X + np.random.normal(0,10**-2,X.shape)\n",
        "# train best model on noisy data\n",
        "best_svm_model = LinearSVC(C=best_C)\n",
        "best_svm_model.fit(X,Y)\n",
        "\n",
        "\n",
        "best_svm_model_accuracy_edited = best_svm_model.score(X,Y)\n",
        "print(f\" best svm model accuracy edited \", best_svm_model_accuracy_edited)\n",
        "best_svm_model_weights_edited = best_svm_model.coef_\n",
        "print(f\"Best svm model coefficents edited\", best_svm_model_weights_edited)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " best svm model accuracy edited  1.0\n",
            "Best svm model coefficents edited [[ 0.01325107 -0.01278229  0.01791113  0.01308231 -0.01282336  0.01390612\n",
            "   0.01168814]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q9O_oE487o6"
      },
      "source": [
        "<pre>\n",
        "5. <b> Checking deviations in metric and weights </b>\n",
        "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
        "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
        "    c. print the top 4 features which have higher % change in weights \n",
        "    compare to the other feature\n",
        "\n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNwmqe2B8_WQ",
        "outputId": "13327589-4370-46e3-deda-69c8f2387dd4"
      },
      "source": [
        "difference_svm_accuracy = abs(best_svm_model_accuracy_edited - best_svm_model_accuracy)\n",
        "print(\"difference between 'best_model_accuracy_edited' and 'best_model_accuracy' for svm\", difference_svm_accuracy)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "difference between 'best_model_accuracy_edited' and 'best_model_accuracy' for svm 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpA7tXti9iB1",
        "outputId": "8c436946-8105-4400-9ac2-7c6e6a5b280f"
      },
      "source": [
        "\n",
        "abs_weight_difference_svm = abs(best_svm_model_weights - best_svm_model_weights_edited)\n",
        "print(f\"absolute weights difference svm\", abs_weight_difference_svm)\n",
        "abs_weight_percent_diff_svm = abs_weight_difference_svm*100\n",
        "print(f\"absolute weights percent difference svm\", abs_weight_percent_diff_svm)\n",
        "\n",
        "top4_svm = np.argsort(-abs_weight_percent_diff_svm)[:,:4]\n",
        "print('Top 4 feature index ',top4[:4]) #Top 4 feture index with highest difference in weights\n",
        "\n",
        "features_svm = data.columns\n",
        "\n",
        "print(\"Top 4 features having highest absolute percentage weight change  for svm model\", features_svm[top4_svm])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absolute weights difference svm [[2.05101790e-05 2.74465914e-05 2.59356185e-06 2.64227525e-05\n",
            "  1.36247731e-05 7.06079751e-06 9.86873931e-06]]\n",
            "absolute weights percent difference svm [[0.00205102 0.00274466 0.00025936 0.00264228 0.00136248 0.00070608\n",
            "  0.00098687]]\n",
            "Top 4 feature index  [[4 2 3 6]]\n",
            "Top 4 features having highest absolute percentage weight change  for svm model [['y' 'x*x' 'x' '2*y']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk5CWqUN-CJd"
      },
      "source": [
        "#<pre> <font color='red'> Observation </font> </pre>\n",
        "\n",
        "1. \n",
        "Multi colinearity is not affecting Accuracy of the model for our dataset for both linear and svm model.\n",
        "2. \n",
        "By observing Top4 features with maximum abs percentage weights difference of original data and noisy data we can conclude that features having multi colinearity and high corelation is affected by outliers ( added noise) and coefficient are changing for those features."
      ]
    }
  ]
}