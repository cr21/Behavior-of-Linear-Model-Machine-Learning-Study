{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "RegressionOutlierEffect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cr21/Behavior-of-Linear-Model-Machine-Learning-Study/blob/main/RegressionOutlierEffect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_YhEgEBf_8"
      },
      "source": [
        "## Study  Regression outlier effect.\n",
        "\n",
        "<font face='georgia'> <h3> Objective:Visualization best fit linear regression line for different scenarios</h3> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYtT_CaPBf__"
      },
      "source": [
        "# you should not import any other packages\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZpRUzXyBgAF"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.optimize\n",
        "\n",
        "def angles_in_ellipse(num,a,b):\n",
        "    assert(num > 0)\n",
        "    assert(a < b)\n",
        "    angles = 2 * np.pi * np.arange(num) / num\n",
        "    # print(\"np.pi\", np.pi)\n",
        "    # print(\" __\",2*np.pi*np.arange(num)/num)\n",
        "    if a != b:\n",
        "        e = (1.0 - a ** 2.0 / b ** 2.0) ** 0.5\n",
        "        print(\"e\",e)\n",
        "        tot_size = sp.special.ellipeinc(2.0 * np.pi, e)\n",
        "        arc_size = tot_size / num\n",
        "        arcs = np.arange(num) * arc_size\n",
        "        res = sp.optimize.root(\n",
        "            lambda x: (sp.special.ellipeinc(x, e) - arcs), angles)\n",
        "        angles = res.x \n",
        "    return angles"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNlL36CzKY8l"
      },
      "source": [
        "# <!-- https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares -->"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKBecYCGBgAL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9916c7d7-56ac-4180-c220-a9555b7a7ae6"
      },
      "source": [
        "a = 2\n",
        "b = 9\n",
        "n = 50\n",
        "\n",
        "phi = angles_in_ellipse(n, a, b)\n",
        "e = (1.0 - a ** 2.0 / b ** 2.0) ** 0.5\n",
        "arcs = sp.special.ellipeinc(phi, e)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca()\n",
        "ax.axes.set_aspect('equal')\n",
        "ax.scatter(b * np.sin(phi), a * np.cos(phi))\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e 0.9749960430435691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ZL3oSWBgAR"
      },
      "source": [
        "X= b * np.sin(phi)\n",
        "Y= a * np.cos(phi)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXCYGQpdBgAW"
      },
      "source": [
        "<pre>\n",
        "<font face='georgia'>\n",
        "<i>\n",
        "1. As a part of this assignment you will be working the regression problem and how regularization helps to get rid of outliers\n",
        "\n",
        "2. Use the above created X, Y for this experiment.\n",
        "\n",
        "3. to do this task you can either implement your own SGDRegression(prefered) excatly similar to \"SGD assignment\" with mean sequared error or \n",
        "you can use the SGDRegression of sklearn, for example \"SGDRegressor(alpha=0.001, eta0=0.001, learning_rate='constant',random_state=0)\" \n",
        "note that you have to use the constant learning rate and learning rate <b>eta0</b> initialized.\n",
        "\n",
        "4. as a part of this experiment you will train your linear regression on the data (X, Y) with different regularizations alpha=[0.0001, 1, 100] and \n",
        "observe how prediction hyper plan moves with respect to the outliers\n",
        "\n",
        "5. This the results of one of the experiment we did (title of the plot was not metioned intentionally) \n",
        "<img src='https://i.imgur.com/FctjBiD.png'> \n",
        "in each iteration we were adding single outlier and observed the movement of the hyper plane.\n",
        "\n",
        "6. please consider this list of outliers: [(0,2),(21, 13), (-23, -15), (22,14), (23, 14)] in each of tuple the first elemet \n",
        "is the input feature(X) and the second element is the output(Y)\n",
        "\n",
        "7. for each regularizer, you need to add these outliers one at time to data and then train your model \n",
        "again on the updated data. \n",
        "\n",
        "8. you should plot a 3*5 grid of subplots,\n",
        " where each row corresponds to results of model with a single regularizer.\n",
        "\n",
        "9. Algorithm: \n",
        "\n",
        "for each regularizer:\n",
        "    for each outlier:\n",
        "        #add the outlier to the data\n",
        "        #fit the linear regression to the updated data\n",
        "        #get the hyper plane\n",
        "        #plot the hyperplane along with the data points\n",
        "\n",
        "10. MAKE SURE YOU WRITE THE DETAILED OBSERVATIONS, PLEASE CHECK THE LOSS FUNCTION IN THE SKLEARN DOCUMENTATION\n",
        " (please do search for it).\n",
        "</i>\n",
        "</font>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57BWufNIdTKn"
      },
      "source": [
        "class CustomSGDRegressor(object):\n",
        "  \"\"\"\n",
        "  Custom Vanila implementation of SGD classfier with minimum detail\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, loss ='squared_loss', penalty='l2',alpha=0.0001, tol=10e-4,learning_rate=0.01, eta0=0.01):\n",
        "    self.loss = loss\n",
        "    self.penalty = penalty\n",
        "    self.alpha = alpha\n",
        "    self.tol = tol\n",
        "    self.learning_rate = learning_rate\n",
        "    self.eta0 = eta0\n",
        "  \n",
        "\n",
        "  def loss(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    get the Loss value\n",
        "    \n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  def initializeParam(X):\n",
        "\n",
        "    \"\"\"\n",
        "    Initialize the parameter for Linear Model\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  def fit(X,Y):\n",
        "\n",
        "    \"\"\"\n",
        "      Fit the line or hyperplane on X\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "  def score(X,Y):\n",
        "    \"\"\"\n",
        "      Return the coefficient of determination  of the prediction\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "  def predict(X):\n",
        "    \"\"\"\n",
        "    Predict the value of X\n",
        "\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q-XKJGFdYGk"
      },
      "source": [
        "SGDRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}